{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPO1Rx91pOTj87LXMO94PAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyun-Jun-Lee/Facial_Dection_PJ/blob/master/Gender_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXLIqUfXI20L"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waPrx63jJV4x"
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg-qWZGQJfIY"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4uoltQrJfPZ"
      },
      "source": [
        "!kaggle datasets download -d cashutosh/gender-classification-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2NpibhhKKSw"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjPRTlczLG0g"
      },
      "source": [
        "!unzip gender-classification-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzU_jBSTLOoe"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIT0MKu0O53y"
      },
      "source": [
        "# 라이브러리 정리\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import *\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from google.colab import files\n",
        "from skimage import io\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyqjfHfdO5_V"
      },
      "source": [
        "# 경로설정 \n",
        "base_dir = \"/content/\"\n",
        "train_dir = \"/content/Training\"\n",
        "validation_dir = \"/content/Validation\"\n",
        "\n",
        "train_male_dir = os.path.join(train_dir, \"male\")\n",
        "train_female_dir = os.path.join(train_dir, \"female\")\n",
        "\n",
        "valid_male_dir = os.path.join(validation_dir, \"male\")\n",
        "valid_female_dir = os.path.join(validation_dir, \"female\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ9RrHfJO6Bu"
      },
      "source": [
        "train_male_fnames = os.listdir(train_male_dir)\n",
        "train_female_fnames = os.listdir(train_female_dir)\n",
        "\n",
        "valid_male_fnames = os.listdir(valid_male_dir)\n",
        "valid_female_fnames = os.listdir(valid_female_dir)\n",
        "\n",
        "print(f\"total training of male is : {len(train_male_fnames)}\")\n",
        "print(f\"total training of female is : {len(train_female_fnames)}\")\n",
        "print(f\"total validation of male is : {len(valid_male_fnames)}\")\n",
        "print(f\"total validation of female is : {len(valid_female_fnames)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_57ix81EO6Dn"
      },
      "source": [
        "# 데이터 확인\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "male_img = [os.path.join(train_male_dir, fname) for fname in train_male_fnames[pic_index-8 : pic_index]]\n",
        "female_img = [os.path.join(train_female_dir, fname) for fname in train_female_fnames[pic_index-8 : pic_index]]\n",
        "\n",
        "\n",
        "for i, img in enumerate(male_img + female_img):\n",
        "    set_subplot = plt.subplot(nrows, ncols, i + 1)\n",
        "    set_subplot.axis(\"Off\")\n",
        "    image = mpimg.imread(img)\n",
        "    plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-ceoGhfVsBa"
      },
      "source": [
        "def gendermodel():\n",
        "    model = Sequential()\n",
        "    input_shape=(300, 300, 3)\n",
        "\n",
        "    model.add(Conv2D(16, (3,3), activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "    \n",
        "    model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dense(84, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "    \n",
        "model = gendermodel()\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7_IoirOX-EA"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnSwoVmwX-MP"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "training_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                      target_size=(300, 300),\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode=\"binary\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                       target_size=(300, 300),\n",
        "                                                       batch_size=20,\n",
        "                                                       class_mode=\"binary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61QsUomoSzlj"
      },
      "source": [
        "history = model.fit_generator(training_generator, steps_per_epoch=100, epochs=30,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=50,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJqclImHZVgY"
      },
      "source": [
        "model.evaluate(training_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiCFWdNCcQ2y"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CTZ2h54cQ5M"
      },
      "source": [
        "def my_model(path):\n",
        "    img = image.load_img(path, target_size=(300, 300))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images_show = np.vstack([x])\n",
        "    predict_classes = model.predict(images_show, batch_size=10)\n",
        "    if predict_classes > 0.5:\n",
        "        print(path + \" Female\")\n",
        "    else:\n",
        "        print(path + \" Male\")\n",
        "\n",
        "    show_img = mpimg.imread(path)\n",
        "    plt.imshow(show_img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys4ODhQ5cQ7w"
      },
      "source": [
        "path = '/content/testing.jpg'\n",
        "\n",
        "my_model(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqLzdduwcQ-Q"
      },
      "source": [
        "path2 = '/content/BIBI.jfif'\n",
        "\n",
        "my_model(path2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc2tzAW6dz8L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}